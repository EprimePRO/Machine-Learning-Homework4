totalRegular <- sum(Cell.regular==1)
malignantRegular <- sum(Class=="malignant" & Cell.regular==1)
malignantRegularPercent <- malignantRegular/totalRegular
totalNotRegular <- sum(Cell.regular==0)
malignantNotRegular <- sum(Class=="malignant" & Cell.regular==0)
malignantNotRegularPercent<- malignantNotRegular/totalNotRegular
set.seed(1234)
i <- sample(1:nrow(BreastCancer), nrow(BreastCancer)*0.8, replace = FALSE)
train <- BreastCancer[i,]
test <- BreastCancer[-i,]
glm1 <- glm(Class~Cell.small+Cell.regular, family = binomial, data=train)
summary(glm1)
probs <- predict(glm1, newdata = test, type="response")
pred <- factor(ifelse(probs>0.5, "malignant", "benign"))
acc1 <- mean(pred==test$Class)
print(paste("glm1 accuracy = ", acc1))
library("caret")
confusionMatrix(pred, test$Class)
glm1$coefficients["Cell.small"]
odds <- exp(glm1$coefficients["Cell.small"])
probCellSmall <- odds/(1+odds)
oddsCellSmallMal <- exp(glm1$coefficients[2] * 1 + glm1$coefficients[1])
probCellSmallMal <- oddsCellSmallMal/(1+oddsCellSmallMal)
numCellSmallMal <- sum(Cell.small==1 & Class=="malignant")
trueProbCellSmallMal <- numCellSmallMal/sum(Cell.small==1)
glm1$coefficients["Cell.small"]
odds <- exp(glm1$coefficients["Cell.small"])
probCellSmall <- odds/(1+odds)
//step c
glm1$coefficients["Cell.small"]
odds <- exp(glm1$coefficients["Cell.small"])
probCellSmall <- odds/(1+odds)
#step c
oddsCellSmallMal <- exp(glm1$coefficients[2] * 1 + glm1$coefficients[1])
probCellSmallMal <- oddsCellSmallMal/(1+oddsCellSmallMal)
#step d
numCellSmallMal <- sum(Cell.small==1 & Class=="malignant")
trueProbCellSmallMal <- numCellSmallMal/sum(Cell.small==1)
glm2 <- glm(Class~Cell.small, family = binomial)
glm2 <- glm(Class~Cell.small, family = binomial)
glm3 <- glm(Class~Cell.regular, family = binomial)
glm_small <- glm(Class~Cell.small, family = binomial)
glm_regular <- glm(Class~Cell.regular, family = binomial)
anova(glm_regular, glm_small, glm1)
library(mlbench)
data("BreastCancer")
str(BreastCancer)
head(BreastCancer)
summary(BreastCancer$Class)
benignTotal <- sum(BreastCancer$Class=="benign")
malignantTotal <- sum(BreastCancer$Class=="malignant")
benignPercent <- benignTotal/(benignTotal+malignantTotal)
malignantPercent <- 1 - benignPercent
print(paste("Benign Percent: ", benignPercent, " Malignant Percent: ", malignantPercent))
glm0 <- glm(Class~Cell.size+Cell.shape, data = BreastCancer, family = binomial)
summary(glm0)
BreastCancer["Cell.small"] <- 1
BreastCancer$Cell.small[BreastCancer$Cell.size>1] <- 0
BreastCancer["Cell.regular"] <- 1
BreastCancer$Cell.regular[BreastCancer$Cell.shape>1] <- 0
summary(BreastCancer[c("Cell.size", "Cell.small", "Cell.shape", "Cell.regular")])
attach(BreastCancer)
par(mfrow=c(1,2))
cdplot(Class~Cell.size)
cdplot(Class~Cell.shape)
par(mfrow=c(1,2))
plot(Class~Cell.small)
plot(Class~Cell.regular)
cdplot(Class~Cell.small)
cdplot(Class~Cell.regular)
totalSmall <- sum(Cell.small==1)
malignantSmall <- sum(Class=="malignant" & Cell.small==1)
malignantSmallPercent <- malignantSmall/totalSmall
totalNotSmall <- sum(Cell.small==0)
malignantNotSmall <- sum(Class=="benign" & Cell.small==0)
malignantNotSmallPercent <- malignantNotSmall/totalNotSmall
totalRegular <- sum(Cell.regular==1)
malignantRegular <- sum(Class=="malignant" & Cell.regular==1)
malignantRegularPercent <- malignantRegular/totalRegular
totalNotRegular <- sum(Cell.regular==0)
malignantNotRegular <- sum(Class=="malignant" & Cell.regular==0)
malignantNotRegularPercent<- malignantNotRegular/totalNotRegular
set.seed(1234)
i <- sample(1:nrow(BreastCancer), nrow(BreastCancer)*0.8, replace = FALSE)
train <- BreastCancer[i,]
test <- BreastCancer[-i,]
glm1 <- glm(Class~Cell.small+Cell.regular, family = binomial, data=train)
summary(glm1)
probs <- predict(glm1, newdata = test, type="response")
pred <- factor(ifelse(probs>0.5, "malignant", "benign"))
acc1 <- mean(pred==test$Class)
print(paste("glm1 accuracy = ", acc1))
library("caret")
confusionMatrix(pred, test$Class)
#step a
glm1$coefficients["Cell.small"]
#step b
odds <- exp(glm1$coefficients["Cell.small"])
odds/(1+odds)
#step c
oddsCellSmallMal <- exp(glm1$coefficients[2] * 1 + glm1$coefficients[1])
oddsCellSmallMal/(1+oddsCellSmallMal)
#step d
numCellSmallMal <- sum(Cell.small==1 & Class=="malignant")
numCellSmallMal/sum(Cell.small==1)
glm_small <- glm(Class~Cell.small, family = binomial)
glm_regular <- glm(Class~Cell.regular, family = binomial)
anova(glm_regular, glm_small, glm1)
glm_small <- glm(Class~Cell.small, family = binomial, data = train)
glm_regular <- glm(Class~Cell.regular, family = binomial, data = train)
anova(glm_regular, glm_small, glm1)
glm_small <- glm(Class~Cell.small, family = binomial, data = train)
glm_regular <- glm(Class~Cell.regular, family = binomial, data = train)
anova(glm_regular, glm_small, glm1)
AIC(glm_small)
AIC(glm_regular)
AIC(glm1)
library(e1071)
library(e1071)
nb1 <- naiveBayes(Class~Cell.small+Cell.regular, data=train)
nb1
0.01030928 + 0.1012712
0.83561644 + 0.3711320
library(e1071)
nb1 <- naiveBayes(Class~Cell.small+Cell.regular, data=train)
nb1
p2_class <- predict(nb1, newdata = test, type = "class")
p2_class <- predict(nb1, newdata = test, type = "class")
acc2 <- mean(p2_class==test$Class)
print(paste("Naive Bayes accuracy = ", acc2))
library(e1071)
nb1 <- naiveBayes(Class ~ Cell.small + Cell.regular , data=train)
nb1
View(nb1)
p2_class <- predict(nb1, newdata = test, type = "class")
acc2 <- mean(p2_class==test$Class)
print(paste("Naive Bayes accuracy = ", acc2))
confusionMatrix(p2_class, test$Class)
install.packages("HSAUR")
labels <- as.integer(df$ESR)
df <- read.csv("titanic_project.csv")
setwd
setwd(C:\Users\emanu\Documents\School\UTD S20\Machine Learning\HW4\Machine-Learning-Homework4)
setwd("C:\Users\emanu\Documents\School\UTD S20\Machine Learning\HW4\Machine-Learning-Homework4")
setwd("~\Documents\School\UTD S20\Machine Learning\HW4\Machine-Learning-Homework4")
?setwd
?setwd
getwd()
setwd("/Documents/School/UTD S20/Machine Learning/HW4/Machine-Learning-Homework4")
setwd("~/Documents/School/UTD S20/Machine Learning/HW4/Machine-Learning-Homework4")
setwd("C:/Users/emanu/Documents/School/UTD S20/Machine Learning/HW4/Machine-Learning-Homework4")
df <- read.csv("titanic_project.csv")
nb1 <-
a
test <- df[-i,]
#run naive Bayes and print results
nb1 <- naiveBayes(survived~pclass+sex+age)
df <- read.csv("titanic_project.csv")
library(e1071)
set.seed(1234)
#Split into train and test
i <- sample(1:nrow(df), nrow(df)*0.8, replace = FALSE)
train <- df[i,]
test <- df[-i,]
#run naive Bayes and print results
nb1 <- naiveBayes(survived~pclass+sex+age)
nb1 <- naiveBayes(survived~pclass+sex+age, data=train)
nb1
#test on the test data
pred <- predict(nb1, newdata = test, type = "class")
df <- read.csv("titanic_project.csv")
library(e1071)
set.seed(1234)
#Split into train and test
i <- sample(1:nrow(df), nrow(df)*0.8, replace = FALSE)
train <- df[i,]
test <- df[-i,]
#run naive Bayes and print results
nb1 <- naiveBayes(survived~pclass+sex+age, data=train)
nb1
#test on the test data
pred <- predict(nb1, newdata = test, type = "class")
df <- read.csv("titanic_project.csv")
library(e1071)
set.seed(1234)
#Split into train and test
i <- sample(1:nrow(df), nrow(df)*0.8, replace = FALSE)
train <- df[i,]
test <- df[-i,]
#run naive Bayes and print results
nb1 <- naiveBayes(survived~pclass+sex+age, data=train)
nb1
#test on the test data
pred <- predict(nb1, newdata = test, type = "class")
pred <- predict(nb1, newdata = test, type = "class")
acc <- mean(pred==test$Class)
print(paste("Naive Bayes accuracy = ", acc))
View(df)
?df
?data
View(df)
df <- read.csv("titanic_project.csv")
library(e1071)
set.seed(1234)
#Split into train and test
i <- sample(1:nrow(df), nrow(df)*0.8, replace = FALSE)
train <- df[i,]
test <- df[-i,]
#run naive Bayes and print results
nb1 <- naiveBayes(survived~pclass+sex+age, data=train)
nb1
#test on the test data
p2_class <- predict(nb1, newdata = test, type = "class")
acc2 <- mean(p2_class==test$Class)
print(paste("Naive Bayes accuracy = ", acc2))
df <- read.csv("titanic_project.csv")
#make survived a factor
df$survived <- as.factor(df$survived)
library(e1071)
set.seed(1234)
#Split into train and test
i <- sample(1:nrow(df), nrow(df)*0.8, replace = FALSE)
train <- df[i,]
test <- df[-i,]
#run naive Bayes and print results
nb1 <- naiveBayes(survived~pclass+sex+age, data=train)
nb1
#test on the test data
p2_class <- predict(nb1, newdata = test, type = "class")
acc2 <- mean(p2_class==test$Class)
print(paste("Naive Bayes accuracy = ", acc2))
df <- read.csv("titanic_project.csv")
#make survived a factor
df$survived <- as.factor(df$survived)
library(e1071)
set.seed(1234)
#Split into train and test
i <- sample(1:nrow(df), nrow(df)*0.8, replace = FALSE)
train <- df[i,]
test <- df[-i,]
#run naive Bayes and print results
nb1 <- naiveBayes(survived~pclass+sex+age, data=train)
nb1
#test on the test data
p2_class <- predict(nb1, newdata = test, type = "class")
acc2 <- mean(p2_class==test$survived)
print(paste("Naive Bayes accuracy = ", acc2))
#print metrics using confusionMatrix
library(caret)
confusionMatrix(nb1, df$survived)
df <- read.csv("titanic_project.csv")
#make survived a factor
df$survived <- as.factor(df$survived)
library(e1071)
set.seed(1234)
#Split into train and test
i <- sample(1:nrow(df), nrow(df)*0.8, replace = FALSE)
train <- df[i,]
test <- df[-i,]
#run naive Bayes and print results
nb1 <- naiveBayes(survived~pclass+sex+age, data=train)
nb1
#test on the test data
pred <- predict(nb1, newdata = test, type = "class")
acc <- mean(pred==test$survived)
print(paste("Naive Bayes accuracy = ", acc))
#print metrics using confusionMatrix
library(caret)
confusionMatrix(pred, df$survived)
confusionMatrix(pred, test$survived)
df <- read.csv("titanic_project.csv")
#make survived a factor
df$survived <- as.factor(df$survived)
library(e1071)
set.seed(1234)
#Split into train and test
i <- sample(1:nrow(df), 900, replace = FALSE)
train <- df[i,]
test <- df[-i,]
#run naive Bayes and print results
nb1 <- naiveBayes(survived~pclass+sex+age, data=train)
nb1
#test on the test data
pred <- predict(nb1, newdata = test, type = "class")
acc <- mean(pred==test$survived)
print(paste("Naive Bayes accuracy = ", acc))
#print metrics using confusionMatrix
library(caret)
confusionMatrix(pred, test$survived)
boxplot(survived~sex)
boxplot(survived~age)
boxplot(survived~sex, data = df)
boxplot(survived~age, data = df)
par(mfrow=c(1,2))
plot(survived~sex, data = df)
plot(survived~age, data = df)
par(mfrow=c(1,2))
plot(survived, sex, data = df)
plot(survived, age, data = df)
par(mfrow=c(1,2))
plot(df$survived, sex, data = df)
plot(df$survived, age, data = df)
par(mfrow=c(1,2))
plot(df$survived, df$sex, data = df)
plot(df$survived, df$age, data = df)
(1,2))
plot(df$survived, df$sex, data = df)
plot(df$survived, df$pclass, data = df)
par(mfrow=c(1,2))
plot(df$survived~df$sex, data = df)
plot(df$survived~df$pclass, data = df)
ow=c(1,2))
plot(survived~sex, data = df)
plot(survived~pclass, data = df)
par(mfrow=c(1,2))
cdplot(survived~sex, data = df)
cdplot(survived~pclass, data = df)
head(df)
tail(df)
summary(df)
df <- read.csv("titanic_project.csv")
#make survived a factor
df$survived <- as.factor(df$survived)
#load naive bayes
library(e1071)
set.seed(1234)
#plot data
par(mfrow=c(1,2))
cdplot(survived~sex, data = df)
cdplot(survived~pclass, data = df)
#explore data
names(df)
head(df)
tail(df)
summary(df)
#Split into train and test
i <- sample(1:nrow(df), 900, replace = FALSE)
train <- df[i,]
test <- df[-i,]
#run naive Bayes and print results
nb1 <- naiveBayes(survived~pclass+sex+age, data=train)
nb1
#test on the test data
pred <- predict(nb1, newdata = test, type = "class")
acc <- mean(pred==test$survived)
print(paste("Naive Bayes accuracy = ", acc))
#print metrics using confusionMatrix
library(caret)
confusionMatrix(pred, test$survived)
library(HSAUR)
data("plasma")
df <- data.frame(plasma)
set.seed(1234)
glm1 <- glm(ESR~fibrinogen, family="binomial", data = df)
summary(glm1)
#linear regression from scrat
sigmoid <- function(z){
1.0 / (1+exp(-z))
}
weights <- c(1,1)
data_matrix <- cbind(rep(1, nrow(df)), df$fibrinogen)
labels <- as.integer(df$ESR)
#Gradient descent
learning_rate <- 0.001
for(i in 1:500000){
prob_vector <- sigmoid(data_matrix %*% weights)
error <- labels - prob_vector
weights <- weights + learning_rate * t(data_matrix) %*% error
}
weights
#log odds
plasma_log_odds <- cbind(rep(1,32), plasma$fibrinogen) %*% weights
plot(plasma$fibrinogen, plasma_log_odds, col=plasma$ESR)
abline(weights[1], weights[2])
View(weights)
View(data_matrix)
df <- read.csv("titanic_project.csv")
#make survived a factor
df$survived <- as.factor(df$survived)
#load naive bayes
library(e1071)
set.seed(1234)
#plot data
par(mfrow=c(1,2))
cdplot(survived~sex, data = df)
cdplot(survived~pclass, data = df)
#explore data
names(df)
head(df)
tail(df)
summary(df)
#Split into train and test
i <- sample(1:nrow(df), 900, replace = FALSE)
train <- df[i,]
test <- df[-i,]
#run naive Bayes and print results
nb1 <- naiveBayes(survived~pclass+sex+age, data=train)
nb1
#test on the test data
pred <- predict(nb1, newdata = test, type = "class")
acc <- mean(pred==test$survived)
print(paste("Naive Bayes accuracy = ", acc))
#print metrics using confusionMatrix
library(caret)
confusionMatrix(pred, test$survived)
library(HSAUR)
data("plasma")
df <- data.frame(plasma)
set.seed(1234)
glm1 <- glm(ESR~fibrinogen, family="binomial", data = df)
summary(glm1)
#linear regression from scrat
sigmoid <- function(z){
1.0 / (1+exp(-z))
}
weights <- c(1,1)
data_matrix <- cbind(rep(1, nrow(df)), df$fibrinogen)
labels <- as.integer(df$ESR)
#Gradient descent
learning_rate <- 0.001
for(i in 1:500000){
prob_vector <- sigmoid(data_matrix %*% weights)
error <- labels - prob_vector
weights <- weights + learning_rate * t(data_matrix) %*% error
}
weights
#log odds
plasma_log_odds <- cbind(rep(1,32), plasma$fibrinogen) %*% weights
plot(plasma$fibrinogen, plasma_log_odds, col=plasma$ESR)
abline(weights[1], weights[2])
library(HSAUR)
data("plasma")
df <- data.frame(plasma)
set.seed(1234)
glm1 <- glm(ESR~fibrinogen, family="binomial", data = df)
summary(glm1)
#linear regression from scrat
sigmoid <- function(z){
1.0 / (1+exp(-z))
}
weights <- c(1,1)
data_matrix <- cbind(rep(1, nrow(df)), df$fibrinogen)
labels <- as.integer(df$ESR)
#Gradient descent
learning_rate <- 0.001
for(i in 1:500000){
prob_vector <- sigmoid(data_matrix %*% weights)
error <- labels - prob_vector
weights <- weights + learning_rate * t(data_matrix) %*% error
}
weights
#log odds
plasma_log_odds <- cbind(rep(1,32), plasma$fibrinogen) %*% weights
plot(plasma$fibrinogen, plasma_log_odds, col=plasma$ESR)
abline(weights[1], weights[2])
library(HSAUR)
data("plasma")
df <- data.frame(plasma)
set.seed(1234)
glm1 <- glm(ESR~fibrinogen, family="binomial", data = df)
summary(glm1)
#linear regression from scrat
sigmoid <- function(z){
1.0 / (1+exp(-z))
}
weights <- c(1,1)
data_matrix <- cbind(rep(1, nrow(df)), df$fibrinogen)
labels <- as.integer(df$ESR) - 1
#Gradient descent
learning_rate <- 0.001
for(i in 1:500000){
prob_vector <- sigmoid(data_matrix %*% weights)
error <- labels - prob_vector
weights <- weights + learning_rate * t(data_matrix) %*% error
}
weights
#log odds
plasma_log_odds <- cbind(rep(1,32), plasma$fibrinogen) %*% weights
plot(plasma$fibrinogen, plasma_log_odds, col=plasma$ESR)
abline(weights[1], weights[2])
library(HSAUR)
attach("plasma")
#data exploration
str(plasma)
head(plasma)
set.seed(1234)
glm1 <- glm(ESR~fibrinogen, family="binomial", data = plasma)
summary(glm1)
summary(plasma$ESR)
summary(plasma$fibrinogen)
#linear regression from scrat
sigmoid <- function(z){
1.0 / (1+exp(-z))
}
weights <- c(1,1)
data_matrix <- cbind(rep(1, nrow(plasma)), plasma$fibrinogen)
labels <- as.integer(plasma$ESR) - 1
weights <- c(1,1)
#Gradient descent
learning_rate <- 0.001
for(i in 1:500000){
prob_vector <- sigmoid(data_matrix %*% weights)
error <- labels - prob_vector
weights <- weights + learning_rate * t(data_matrix) %*% error
}
weights
#log odds
plasma_log_odds <- cbind(rep(1,32), plasma$fibrinogen) %*% weights
par(mfrow=c(1,2))
cdplot(plasma$ESR~plasma$fibrinogen)
plot(plasma$fibrinogen, plasma_log_odds, col=plasma$ESR)
abline(weights[1], weights[2])
